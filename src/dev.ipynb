{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generacion de dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file yellow_tripdata_2023_01.parquet filtered out because 1959-12-01 > 2023-01-01 or  2023-01-01 > 2020-10-01\n",
      "file yellow_tripdata_2023_02.parquet filtered out because 1959-12-01 > 2023-02-01 or  2023-02-01 > 2020-10-01\n",
      "file yellow_tripdata_2023_03.parquet filtered out because 1959-12-01 > 2023-03-01 or  2023-03-01 > 2020-10-01\n",
      "file yellow_tripdata_2023_04.parquet filtered out because 1959-12-01 > 2023-04-01 or  2023-04-01 > 2020-10-01\n",
      "file yellow_tripdata_2023_05.parquet filtered out because 1959-12-01 > 2023-05-01 or  2023-05-01 > 2020-10-01\n",
      "file yellow_tripdata_2023_06.parquet filtered out because 1959-12-01 > 2023-06-01 or  2023-06-01 > 2020-10-01\n",
      "file yellow_tripdata_2023_07.parquet filtered out because 1959-12-01 > 2023-07-01 or  2023-07-01 > 2020-10-01\n",
      "file yellow_tripdata_2023_08.parquet filtered out because 1959-12-01 > 2023-08-01 or  2023-08-01 > 2020-10-01\n",
      "file yellow_tripdata_2023_09.parquet filtered out because 1959-12-01 > 2023-09-01 or  2023-09-01 > 2020-10-01\n",
      "file yellow_tripdata_2022_01.parquet filtered out because 1959-12-01 > 2022-01-01 or  2022-01-01 > 2020-10-01\n",
      "file yellow_tripdata_2022_02.parquet filtered out because 1959-12-01 > 2022-02-01 or  2022-02-01 > 2020-10-01\n",
      "file yellow_tripdata_2022_03.parquet filtered out because 1959-12-01 > 2022-03-01 or  2022-03-01 > 2020-10-01\n",
      "file yellow_tripdata_2022_04.parquet filtered out because 1959-12-01 > 2022-04-01 or  2022-04-01 > 2020-10-01\n",
      "file yellow_tripdata_2022_05.parquet filtered out because 1959-12-01 > 2022-05-01 or  2022-05-01 > 2020-10-01\n",
      "file yellow_tripdata_2022_06.parquet filtered out because 1959-12-01 > 2022-06-01 or  2022-06-01 > 2020-10-01\n",
      "file yellow_tripdata_2022_07.parquet filtered out because 1959-12-01 > 2022-07-01 or  2022-07-01 > 2020-10-01\n",
      "file yellow_tripdata_2022_08.parquet filtered out because 1959-12-01 > 2022-08-01 or  2022-08-01 > 2020-10-01\n",
      "file yellow_tripdata_2022_09.parquet filtered out because 1959-12-01 > 2022-09-01 or  2022-09-01 > 2020-10-01\n",
      "file yellow_tripdata_2022_10.parquet filtered out because 1959-12-01 > 2022-10-01 or  2022-10-01 > 2020-10-01\n",
      "file yellow_tripdata_2022_11.parquet filtered out because 1959-12-01 > 2022-11-01 or  2022-11-01 > 2020-10-01\n",
      "file yellow_tripdata_2022_12.parquet filtered out because 1959-12-01 > 2022-12-01 or  2022-12-01 > 2020-10-01\n",
      "file yellow_tripdata_2021_01.parquet filtered out because 1959-12-01 > 2021-01-01 or  2021-01-01 > 2020-10-01\n",
      "file yellow_tripdata_2021_02.parquet filtered out because 1959-12-01 > 2021-02-01 or  2021-02-01 > 2020-10-01\n",
      "file yellow_tripdata_2021_03.parquet filtered out because 1959-12-01 > 2021-03-01 or  2021-03-01 > 2020-10-01\n",
      "file yellow_tripdata_2021_04.parquet filtered out because 1959-12-01 > 2021-04-01 or  2021-04-01 > 2020-10-01\n",
      "file yellow_tripdata_2021_05.parquet filtered out because 1959-12-01 > 2021-05-01 or  2021-05-01 > 2020-10-01\n",
      "file yellow_tripdata_2021_06.parquet filtered out because 1959-12-01 > 2021-06-01 or  2021-06-01 > 2020-10-01\n",
      "file yellow_tripdata_2021_07.parquet filtered out because 1959-12-01 > 2021-07-01 or  2021-07-01 > 2020-10-01\n",
      "file yellow_tripdata_2021_08.parquet filtered out because 1959-12-01 > 2021-08-01 or  2021-08-01 > 2020-10-01\n",
      "file yellow_tripdata_2021_09.parquet filtered out because 1959-12-01 > 2021-09-01 or  2021-09-01 > 2020-10-01\n",
      "file yellow_tripdata_2021_10.parquet filtered out because 1959-12-01 > 2021-10-01 or  2021-10-01 > 2020-10-01\n",
      "file yellow_tripdata_2021_11.parquet filtered out because 1959-12-01 > 2021-11-01 or  2021-11-01 > 2020-10-01\n",
      "file yellow_tripdata_2021_12.parquet filtered out because 1959-12-01 > 2021-12-01 or  2021-12-01 > 2020-10-01\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-01.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2020/01.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-02.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2020/02.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-03.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2020/03.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-04.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2020/04.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-05.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2020/05.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-06.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2020/06.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-07.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2020/07.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-08.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2020/08.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-09.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2020/09.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-10.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2020/10.parquet.\n",
      "file yellow_tripdata_2020_11.parquet filtered out because 1959-12-01 > 2020-11-01 or  2020-11-01 > 2020-10-01\n",
      "file yellow_tripdata_2020_12.parquet filtered out because 1959-12-01 > 2020-12-01 or  2020-12-01 > 2020-10-01\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-01.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2019/01.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-02.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2019/02.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-03.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2019/03.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-04.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2019/04.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-05.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2019/05.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-06.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2019/06.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-07.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2019/07.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-08.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2019/08.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-09.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2019/09.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-10.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2019/10.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-11.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2019/11.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-12.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2019/12.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2018-01.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2018/01.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2018-02.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2018/02.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2018-03.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2018/03.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2018-04.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2018/04.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2018-05.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2018/05.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2018-06.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2018/06.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2018-07.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2018/07.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2018-08.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2018/08.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2018-09.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2018/09.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2018-10.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2018/10.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2018-11.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2018/11.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2018-12.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2018/12.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2017-01.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2017/01.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2017-02.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2017/02.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2017-03.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2017/03.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2017-04.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2017/04.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2017-05.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2017/05.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2017-06.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2017/06.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2017-07.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2017/07.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2017-08.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2017/08.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2017-09.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2017/09.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2017-10.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2017/10.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2017-11.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2017/11.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2017-12.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2017/12.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-01.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2016/01.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-02.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2016/02.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-03.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2016/03.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-04.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2016/04.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-05.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2016/05.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-06.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2016/06.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-07.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2016/07.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-08.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2016/08.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-09.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2016/09.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-10.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2016/10.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-11.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2016/11.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-12.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2016/12.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-01.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2015/01.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-02.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2015/02.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-03.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2015/03.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-04.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2015/04.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-05.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2015/05.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-06.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2015/06.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-07.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2015/07.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-08.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2015/08.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-09.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2015/09.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-10.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2015/10.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-11.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2015/11.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-12.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2015/12.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-01.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2014/01.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-02.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2014/02.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-03.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2014/03.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-04.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2014/04.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-05.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2014/05.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-06.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2014/06.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-07.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2014/07.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-08.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2014/08.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-09.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2014/09.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-10.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2014/10.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-11.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2014/11.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2014-12.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2014/12.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-01.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2013/01.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-02.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2013/02.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-03.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2013/03.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-04.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2013/04.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-05.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2013/05.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-06.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2013/06.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-07.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2013/07.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-08.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2013/08.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-09.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2013/09.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-10.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2013/10.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-11.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2013/11.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2013-12.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2013/12.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-01.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2012/01.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-02.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2012/02.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-03.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2012/03.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-04.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2012/04.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-05.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2012/05.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-06.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2012/06.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-07.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2012/07.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-08.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2012/08.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-09.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2012/09.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-10.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2012/10.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-11.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2012/11.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2012-12.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2012/12.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-01.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2011/01.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-02.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2011/02.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-03.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2011/03.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-04.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2011/04.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-05.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2011/05.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-06.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2011/06.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-07.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2011/07.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-08.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2011/08.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-09.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2011/09.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-10.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2011/10.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-11.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2011/11.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2011-12.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2011/12.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-01.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2010/01.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-02.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2010/02.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-03.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2010/03.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-04.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2010/04.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-05.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2010/05.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-06.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2010/06.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-07.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2010/07.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-08.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2010/08.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-09.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2010/09.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-10.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2010/10.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-11.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2010/11.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-12.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2010/12.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-01.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2009/01.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-02.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2009/02.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-03.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2009/03.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-04.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2009/04.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-05.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2009/05.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-06.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2009/06.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-07.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2009/07.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-08.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2009/08.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-09.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2009/09.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-10.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2009/10.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-11.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2009/11.parquet.\n",
      "The file corresponding to https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-12.parquet already exists at D:\\Repositorios\\dev\\prueba_tecnica_cyd\\src/../datasets/yellow_tripdata/2009/12.parquet.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data in parallel using 12 threads to build yellow_tripdata dataset: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import data_extractor as de\n",
    "import constants as c\n",
    "\n",
    "de.generate_dataset(\n",
    "    c.DATASET.YELLOW_TAXI.PATTERN,\n",
    "    start_date=\"01-12-1959\",\n",
    "    end_date=\"01-10-2020\",\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformacion de datos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Columna                | Descripción                                                                                                                                                           |\n",
    "|------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| VendorID               | Un código que indica el proveedor TPEP que proporcionó el registro. 1= Creative Mobile Technologies, LLC; 2= VeriFone Inc.                                            |\n",
    "| tpep_pickup_datetime   | Fecha y hora en que se activó el taxímetro.                                                                                                                            |\n",
    "| tpep_dropoff_datetime  | Fecha y hora en que se desactivó el taxímetro.                                                                                                                          |\n",
    "| Passenger_count        | Número de pasajeros en el vehículo. Valor ingresado por el conductor.                                                                                                  |\n",
    "| Trip_distance          | Distancia recorrida en millas, reportada por el taxímetro.                                                                                                              |\n",
    "| PULocationID           | Identificación de la Zona de Taxis TLC donde se activó el taxímetro.                                                                                                    |\n",
    "| DOLocationID           | Identificación de la Zona de Taxis TLC donde se desactivó el taxímetro.                                                                                                  |\n",
    "| RateCodeID             | Código tarifario final al final del viaje. 1= Tarifa estándar, 2= JFK, 3= Newark, 4= Nassau o Westchester, 5= Tarifa negociada, 6= Viaje en grupo.                  |\n",
    "| Store_and_fwd_flag     | Indica si el registro del viaje se almacenó en la memoria del vehículo antes de ser enviado al proveedor (\"store and forward\"), por falta de conexión al servidor. |\n",
    "| Payment_type           | Código numérico que indica cómo pagó el pasajero. 1= Tarjeta de crédito, 2= Efectivo, 3= Sin cargo, 4= Disputa, 5= Desconocido, 6= Viaje anulado.                  |\n",
    "| Fare_amount            | Tarifa calculada por tiempo y distancia según el taxímetro.                                                                                                             |\n",
    "| Extra                  | Extras y recargos varios. Actualmente incluye recargos por hora pico y noche ($0.50 y $1).                                                                              |\n",
    "| MTA_tax                | Impuesto MTA de $0.50 que se activa automáticamente según la tarifa del taxímetro en uso.                                                                             |\n",
    "| Improvement_surcharge  | Recargo de mejora de $0.30 para viajes que comenzaron a aplicarse en 2015.                                                                                              |\n",
    "| Tip_amount             | Monto de propina. Este campo se completa automáticamente para propinas con tarjeta de crédito. Las propinas en efectivo no están incluidas.                           |\n",
    "| Tolls_amount           | Total de todos los peajes pagados en el viaje.                                                                                                                           |\n",
    "| Total_amount           | Total cobrado a los pasajeros. No incluye propinas en efectivo.                                                                                                          |\n",
    "| Congestion_Surcharge   | Total recaudado en el viaje por el recargo de congestión del estado de Nueva York.                                                                                        |\n",
    "| Airport_fee            | Tarifa de $1.25 solo para recogidas en los aeropuertos LaGuardia y John F. Kennedy.                                                                                     |\n",
    "\n",
    "\n",
    "\n",
    "------------------\n",
    "\n",
    "\n",
    "| Columna                | Tipo de PySpark    | Justificación                                                                                           |\n",
    "|------------------------|--------------------|---------------------------------------------------------------------------------------------------------|\n",
    "| VendorID               | IntegerType        | Representa un código numérico para identificar el proveedor.                                              |\n",
    "| tpep_pickup_datetime   | TimestampType      | Almacena fechas y horas, útil para análisis de tiempo y series temporales.                                |\n",
    "| tpep_dropoff_datetime  | TimestampType      | Similar a 'tpep_pickup_datetime', almacena fechas y horas para el final del viaje.                       |\n",
    "| Passenger_count        | IntegerType        | Número de pasajeros debe ser un valor entero.                                                             |\n",
    "| Trip_distance          | FloatType          | La distancia del viaje puede ser un valor decimal.                                                         |\n",
    "| PULocationID           | IntegerType        | Identificación de la ubicación de recogida, representada por un número entero.                            |\n",
    "| DOLocationID           | IntegerType        | Identificación de la ubicación de bajada, similar a 'PULocationID'.                                       |\n",
    "| RateCodeID             | IntegerType        | Representa el código de tarifa como un valor numérico.                                                     |\n",
    "| Store_and_fwd_flag     | StringType         | Almacena valores 'Y' o 'N', adecuado para una cadena de caracteres (string).                             |\n",
    "| Payment_type           | IntegerType        | Códigos numéricos que indican diferentes métodos de pago.                                                  |\n",
    "| Fare_amount            | FloatType          | La tarifa puede ser un valor decimal, por lo tanto, se elige un tipo de dato flotante.                   |\n",
    "| Extra                  | FloatType          | Similar a 'Fare_amount', también se considera un valor decimal.                                           |\n",
    "| MTA_tax                | FloatType          | Impuesto MTA puede ser un valor decimal.                                                                   |\n",
    "| Improvement_surcharge  | FloatType          | Recargo de mejora, otro valor decimal.                                                                     |\n",
    "| Tip_amount             | FloatType          | La propina puede ser un valor decimal.                                                                     |\n",
    "| Tolls_amount           | FloatType          | El total de peajes es un valor decimal.                                                                    |\n",
    "| Total_amount           | FloatType          | El total cobrado a los pasajeros es un valor decimal.                                                       |\n",
    "| Congestion_Surcharge   | FloatType          | El recargo de congestión es un valor decimal.                                                               |\n",
    "| Airport_fee            | FloatType          | La tarifa de aeropuerto puede ser un valor decimal.                                                         |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'vendorid' has type 'LongType()' in DataFrame, but type 'IntegerType()' in schema.\n",
      "Column 'tpep_pickup_datetime' has type 'TimestampNTZType()' in DataFrame, but type 'TimestampType()' in schema.\n",
      "Column 'tpep_dropoff_datetime' has type 'TimestampNTZType()' in DataFrame, but type 'TimestampType()' in schema.\n",
      "Column 'passenger_count' has type 'DoubleType()' in DataFrame, but type 'IntegerType()' in schema.\n",
      "Column 'trip_distance' has type 'DoubleType()' in DataFrame, but type 'FloatType()' in schema.\n",
      "Column 'ratecodeid' has type 'DoubleType()' in DataFrame, but type 'IntegerType()' in schema.\n",
      "Column 'pulocationid' has type 'LongType()' in DataFrame, but type 'IntegerType()' in schema.\n",
      "Column 'dolocationid' has type 'LongType()' in DataFrame, but type 'IntegerType()' in schema.\n",
      "Column 'payment_type' has type 'LongType()' in DataFrame, but type 'IntegerType()' in schema.\n",
      "Column 'fare_amount' has type 'DoubleType()' in DataFrame, but type 'FloatType()' in schema.\n",
      "Column 'extra' has type 'DoubleType()' in DataFrame, but type 'FloatType()' in schema.\n",
      "Column 'mta_tax' has type 'DoubleType()' in DataFrame, but type 'FloatType()' in schema.\n",
      "Column 'improvement_surcharge' has type 'DoubleType()' in DataFrame, but type 'FloatType()' in schema.\n",
      "Column 'tip_amount' has type 'DoubleType()' in DataFrame, but type 'FloatType()' in schema.\n",
      "Column 'tolls_amount' has type 'DoubleType()' in DataFrame, but type 'FloatType()' in schema.\n",
      "Column 'total_amount' has type 'DoubleType()' in DataFrame, but type 'FloatType()' in schema.\n",
      "Column 'congestion_surcharge' has type 'DoubleType()' in DataFrame, but type 'FloatType()' in schema.\n",
      "Column 'airport_fee' has type 'IntegerType()' in DataFrame, but type 'FloatType()' in schema.\n",
      "root\n",
      " |-- vendorid: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: float (nullable = true)\n",
      " |-- ratecodeid: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- pulocationid: integer (nullable = true)\n",
      " |-- dolocationid: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: float (nullable = true)\n",
      " |-- extra: float (nullable = true)\n",
      " |-- mta_tax: float (nullable = true)\n",
      " |-- tip_amount: float (nullable = true)\n",
      " |-- tolls_amount: float (nullable = true)\n",
      " |-- improvement_surcharge: float (nullable = true)\n",
      " |-- total_amount: float (nullable = true)\n",
      " |-- congestion_surcharge: float (nullable = true)\n",
      " |-- airport_fee: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "from data_transform import DataTransformer\n",
    "import constants as c\n",
    "\n",
    "dt = DataTransformer()\n",
    "\n",
    "df = dt.load_data(path_parquet=\"../datasets/yellow_tripdata/2020/01.parquet\")\n",
    "\n",
    "# enforce schema\n",
    "df = dt.enforce_schema(df, c.DATASET.YELLOW_TAXI.SQUEMA, verbose=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vendorid: 0 | 0.0%\n",
      "tpep_pickup_datetime: 0 | 0.0%\n",
      "tpep_dropoff_datetime: 0 | 0.0%\n",
      "passenger_count: 65441 | 1.022%\n",
      "trip_distance: 0 | 0.0%\n",
      "ratecodeid: 65441 | 1.022%\n",
      "store_and_fwd_flag: 65441 | 1.022%\n",
      "pulocationid: 0 | 0.0%\n",
      "dolocationid: 0 | 0.0%\n",
      "payment_type: 0 | 0.0%\n",
      "fare_amount: 0 | 0.0%\n",
      "extra: 0 | 0.0%\n",
      "mta_tax: 0 | 0.0%\n",
      "tip_amount: 0 | 0.0%\n",
      "tolls_amount: 0 | 0.0%\n",
      "improvement_surcharge: 0 | 0.0%\n",
      "total_amount: 0 | 0.0%\n",
      "congestion_surcharge: 65441 | 1.022%\n",
      "airport_fee: 6405008 | 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Mostrar el resumen de valores nulos por columna en forma de tabla\n",
    "dt.show_nulls_per_column(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminado de aquellas columnas con mas de un 30% de nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting columns that exceed 30% of null values\n",
      "Column airport_fee marked to remove, 100.0% of null values found\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|vendorid|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|ratecodeid|store_and_fwd_flag|pulocationid|dolocationid|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "|       1| 2020-01-01 00:28:15|  2020-01-01 00:33:03|              1|          1.2|         1|                 N|         238|         239|           1|        6.0|  3.0|    0.5|      1.47|         0.0|                  0.3|       11.27|                 2.5|\n",
      "|       1| 2020-01-01 00:35:39|  2020-01-01 00:43:04|              1|          1.2|         1|                 N|         239|         238|           1|        7.0|  3.0|    0.5|       1.5|         0.0|                  0.3|        12.3|                 2.5|\n",
      "|       1| 2020-01-01 00:47:41|  2020-01-01 00:53:52|              1|          0.6|         1|                 N|         238|         238|           1|        6.0|  3.0|    0.5|       1.0|         0.0|                  0.3|        10.8|                 2.5|\n",
      "|       1| 2020-01-01 00:55:23|  2020-01-01 01:00:14|              1|          0.8|         1|                 N|         238|         151|           1|        5.5|  0.5|    0.5|      1.36|         0.0|                  0.3|        8.16|                 0.0|\n",
      "|       2| 2020-01-01 00:01:58|  2020-01-01 00:04:16|              1|          0.0|         1|                 N|         193|         193|           2|        3.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         4.8|                 0.0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = dt.drop_null_columns(df, threshold_percentage=30)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total_amount should be \"The total amount charged to passengers. Does not include cash tips.\". So I consider it as the sum of the cols:\n",
    "* Fare_amount: The total amount charged to passengers. Does not include cash tips.\n",
    "* Extra: Miscellaneous extras and surcharges. Currently, this only includes the $0.50 and $1 rush hour and overnight charges.\n",
    "* Improvement_surcharge: $0.30 improvement surcharge assessed trips at the flag drop. The improvement surcharge began being levied in 2015.\n",
    "* Tip_amount: Tip amount – This field is automatically populated for credit card tips. Cash tips are not included.\n",
    "* Tolls_amount: Total amount of all tolls paid in trip.\n",
    "* Congestion_Surcharge: Total amount collected in trip for NYS congestion surcharge.\n",
    "* Airport_fee: $1.25 for pick up only at LaGuardia and John F. Kennedy Airports\n",
    "\n",
    "So:\n",
    "\n",
    "```total_amount = Fare_amount + Extra + MTA_tax + Improvement_surcharge + Tip_amount + Tolls_amount + Congestion_Surcharge + Airport_fee```\n",
    "\n",
    "But, since Airport_fee has been removed because all its values were null, then the formula looks like this:\n",
    "\n",
    "\n",
    "```total_amount = Fare_amount + Extra + MTA_tax + Improvement_surcharge + Tip_amount + Tolls_amount + Congestion_Surcharge```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------------------+\n",
      "|vendorid|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|ratecodeid|store_and_fwd_flag|pulocationid|dolocationid|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|total_amount_computed|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------------------+\n",
      "|       1| 2020-01-01 00:28:15|  2020-01-01 00:33:03|              1|          1.2|         1|                 N|         238|         239|           1|        6.0|  3.0|    0.5|      1.47|         0.0|                  0.3|       11.27|                 2.5|                13.77|\n",
      "|       1| 2020-01-01 00:35:39|  2020-01-01 00:43:04|              1|          1.2|         1|                 N|         239|         238|           1|        7.0|  3.0|    0.5|       1.5|         0.0|                  0.3|        12.3|                 2.5|                 14.8|\n",
      "|       1| 2020-01-01 00:47:41|  2020-01-01 00:53:52|              1|          0.6|         1|                 N|         238|         238|           1|        6.0|  3.0|    0.5|       1.0|         0.0|                  0.3|        10.8|                 2.5|                 13.3|\n",
      "|       1| 2020-01-01 00:55:23|  2020-01-01 01:00:14|              1|          0.8|         1|                 N|         238|         151|           1|        5.5|  0.5|    0.5|      1.36|         0.0|                  0.3|        8.16|                 0.0|                 8.16|\n",
      "|       2| 2020-01-01 00:01:58|  2020-01-01 00:04:16|              1|          0.0|         1|                 N|         193|         193|           2|        3.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         4.8|                 0.0|                  4.8|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check wheter total_amount is correctly computed\n",
    "cols_to_sum = [\"fare_amount\", \"extra\", \"mta_tax\", \"tip_amount\", \"tolls_amount\", \"improvement_surcharge\", \"congestion_surcharge\"]\n",
    "df = dt.create_sum_col(df, cols_to_sum)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the values in the total_amount column do not always match the total_amount_computed column, so what we are going to do is to remove total_amount and replace it with total_amount_computed, renaming the latter to total_amount.\n",
    "This choice may not be the most appropriate depending on the circumstances. For example, if you are going to make an extra charge to customers in such a way that this causes a decrease in demand for taxis.\n",
    "\n",
    "To solve this problem correctly, one would have to consider how total_amount was initially calculated and find the error, in order to provide a consistent solution. However, given that we do not have that information, I consider this to be a possible option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+--------------------+------------+\n",
      "|vendorid|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|ratecodeid|store_and_fwd_flag|pulocationid|dolocationid|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|congestion_surcharge|total_amount|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+--------------------+------------+\n",
      "|       1| 2020-01-01 00:28:15|  2020-01-01 00:33:03|              1|          1.2|         1|                 N|         238|         239|           1|        6.0|  3.0|    0.5|      1.47|         0.0|                  0.3|                 2.5|       13.77|\n",
      "|       1| 2020-01-01 00:35:39|  2020-01-01 00:43:04|              1|          1.2|         1|                 N|         239|         238|           1|        7.0|  3.0|    0.5|       1.5|         0.0|                  0.3|                 2.5|        14.8|\n",
      "|       1| 2020-01-01 00:47:41|  2020-01-01 00:53:52|              1|          0.6|         1|                 N|         238|         238|           1|        6.0|  3.0|    0.5|       1.0|         0.0|                  0.3|                 2.5|        13.3|\n",
      "|       1| 2020-01-01 00:55:23|  2020-01-01 01:00:14|              1|          0.8|         1|                 N|         238|         151|           1|        5.5|  0.5|    0.5|      1.36|         0.0|                  0.3|                 0.0|        8.16|\n",
      "|       2| 2020-01-01 00:01:58|  2020-01-01 00:04:16|              1|          0.0|         1|                 N|         193|         193|           2|        3.5|  0.5|    0.5|       0.0|         0.0|                  0.3|                 0.0|         4.8|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = dt.replace_column(df, col_to_replace=\"total_amount\", replace_with=\"total_amount_computed\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEBUG TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# add path to src\n",
    "test_dir = \"../test/\"\n",
    "if test_dir not in sys.path:\n",
    "    sys.path.append(test_dir)\n",
    "\n",
    "import test_data_extractor as tde\n",
    "\n",
    "tde.test_convert_str_date_to_date_valid_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o274.count.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 9 in stage 1.0 failed 1 times, most recent failure: Lost task 9.0 in stage 1.0 (TID 10) (192.168.1.21 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:701)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:745)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:698)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:663)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:639)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:585)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:543)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 34 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:701)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:745)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:698)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:663)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:639)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:585)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:543)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 34 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32md:\\Repositorios\\dev\\prueba_tecnica_cyd\\src\\dev.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repositorios/dev/prueba_tecnica_cyd/src/dev.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappend(test_dir)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repositorios/dev/prueba_tecnica_cyd/src/dev.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtest_data_transform\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtdt\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Repositorios/dev/prueba_tecnica_cyd/src/dev.ipynb#X20sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m tdt\u001b[39m.\u001b[39;49mtest_cast_column()\n",
      "File \u001b[1;32md:\\Repositorios\\dev\\prueba_tecnica_cyd\\src\\../test\\test_data_transform.py:31\u001b[0m, in \u001b[0;36mtest_cast_column\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39massert\u001b[39;00m new_df\u001b[39m.\u001b[39mschema[\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mdataType\u001b[39m.\u001b[39mtypeName() \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstring\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     30\u001b[0m \u001b[39m# Verificar si el número de filas se mantiene igual después del cast\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[39massert\u001b[39;00m df\u001b[39m.\u001b[39;49mcount() \u001b[39m==\u001b[39m new_df\u001b[39m.\u001b[39mcount()\n",
      "File \u001b[1;32md:\\Repositorios\\dev\\prueba_tecnica_cyd\\project_env\\Lib\\site-packages\\pyspark\\sql\\dataframe.py:1234\u001b[0m, in \u001b[0;36mDataFrame.count\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1211\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcount\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[0;32m   1212\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns the number of rows in this :class:`DataFrame`.\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m \n\u001b[0;32m   1214\u001b[0m \u001b[39m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1232\u001b[0m \u001b[39m    3\u001b[39;00m\n\u001b[0;32m   1233\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1234\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mint\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jdf\u001b[39m.\u001b[39;49mcount())\n",
      "File \u001b[1;32md:\\Repositorios\\dev\\prueba_tecnica_cyd\\project_env\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[0;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32md:\\Repositorios\\dev\\prueba_tecnica_cyd\\project_env\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdeco\u001b[39m(\u001b[39m*\u001b[39ma: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    178\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49ma, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[0;32m    180\u001b[0m     \u001b[39mexcept\u001b[39;00m Py4JJavaError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    181\u001b[0m         converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32md:\\Repositorios\\dev\\prueba_tecnica_cyd\\project_env\\Lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[39m=\u001b[39m OUTPUT_CONVERTER[\u001b[39mtype\u001b[39m](answer[\u001b[39m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m answer[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m. Trace:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{3}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o274.count.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 9 in stage 1.0 failed 1 times, most recent failure: Lost task 9.0 in stage 1.0 (TID 10) (192.168.1.21 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:701)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:745)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:698)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:663)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:639)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:585)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:543)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 34 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:203)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:109)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:124)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:174)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:67)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\r\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\r\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\r\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.base/sun.nio.ch.NioSocketImpl.timedAccept(NioSocketImpl.java:701)\r\n\tat java.base/sun.nio.ch.NioSocketImpl.accept(NioSocketImpl.java:745)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:698)\r\n\tat java.base/java.net.ServerSocket.platformImplAccept(ServerSocket.java:663)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:639)\r\n\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:585)\r\n\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:543)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:190)\r\n\t... 34 more\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# add path to src\n",
    "test_dir = \"../test/\"\n",
    "if test_dir not in sys.path:\n",
    "    sys.path.append(test_dir)\n",
    "\n",
    "import test_data_transform as tdt\n",
    "\n",
    "tdt.test_cast_column()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global_aptitude",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
